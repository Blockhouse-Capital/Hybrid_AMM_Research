{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4e9623-e7d9-4a67-bb8f-03486b2884c9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d1a1996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Complete\n"
     ]
    }
   ],
   "source": [
    "# From Imports\n",
    "from math import log, sqrt, pi, exp\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime, date\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "from scipy.optimize import minimize\n",
    "from arch import arch_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Alias Imports\n",
    "import numpy_financial as npf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# Imports\n",
    "import math\n",
    "import arch\n",
    "import openpyxl \n",
    "import pprint\n",
    "\n",
    "print(\"Import Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc6470",
   "metadata": {},
   "source": [
    "# Importing Bond Trading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1c6aabec-2c22-460b-bdaa-1936f624d0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel Data Imported\n"
     ]
    }
   ],
   "source": [
    "# Importing Excel data of 2Y and 10Y Tbills\n",
    "tbill2Y = pd.read_excel(\"Treasury_Data_V1.xlsx\", \"T 4.625 02 28 25 Govt TRADES\")\n",
    "tbill10Y = pd.read_excel(\"Treasury_Data_V1.xlsx\", \"T 3.375 05 15 33 Govt TRADES\")\n",
    "#note, volume is traded in increments of $1000 USD at STGT Exchange\n",
    "#note, need to clean 10Y data, bids / asks don't line up\n",
    "\n",
    "# Making Trade Time, Trade Volume, and Ask Time into lists for 2Y Bond Data\n",
    "dates2Y = list(tbill2Y[\"Trade Time\"])\n",
    "volumes2Y = list(tbill2Y[\"Trade Volume\"])\n",
    "asks2Y = list(tbill2Y[\"Ask Time\"]) # Currently Not Used\n",
    "\n",
    "print(\"Excel Data Imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f38ec4-1ebf-4df6-8093-32a3d43a799d",
   "metadata": {},
   "source": [
    "# Cleaning Bond Trading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c7c224f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Trade Time data\n",
    "clean_dates2Y = []\n",
    "\n",
    "# Going through the range and converting dates to Numpy datetime64s\n",
    "for i in range(len(dates2Y)):\n",
    "    date = np.datetime64(str(dates2Y[i].date()))\n",
    "\n",
    "    # Removing all NaT values from the list\n",
    "    if not np.isnat(date):\n",
    "\n",
    "        # Adding all dates to our clean_dates2Y list\n",
    "        clean_dates2Y.append(date)\n",
    "\n",
    "    # If no date given, we make datetime max value for easy spotting\n",
    "    else:\n",
    "        clean_dates2Y.append(np.datetime64(datetime.max))\n",
    "\n",
    "# Cleaning Ask Time data\n",
    "clean_asks2Y = []\n",
    "\n",
    "# Going through the range and converting dates to Numpy datetime64s\n",
    "for i in range(len(asks2Y)):\n",
    "    date = np.datetime64(str(asks2Y[i].date()))\n",
    "\n",
    "    # Removing all NaT values from the list\n",
    "    if not np.isnat(date):\n",
    "\n",
    "        # Adding all dates to our clean_asks2Y list\n",
    "        clean_asks2Y.append(date)\n",
    "\n",
    "    # If no date given, we make datetime max value for easy spotting\n",
    "    else:\n",
    "        clean_dates2Y.append(np.datetime64(datetime.min))\n",
    "\n",
    "print(\"Data cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa3388c-b01f-4057-8372-68af3ee72d88",
   "metadata": {},
   "source": [
    "# Calculating Average Daily Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a413002-4525-488f-b9d9-f3984801d879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Trading Day  Hourly Volume\n",
      "0                   2023-06-27    10908333.33\n",
      "1                   2023-06-28    22750000.00\n",
      "2                   2023-06-29    74017750.00\n",
      "3                   2023-06-30   196287576.00\n",
      "4                   2023-07-02           0.00\n",
      "5                   2023-07-03    90151483.33\n",
      "6                   2023-07-04  -119503974.67\n",
      "7                   2023-07-05    92332050.00\n",
      "8                   2023-07-06    33538546.83\n",
      "9                   2023-07-07    77604684.83\n",
      "10                  2023-07-09     5357500.00\n",
      "11                  2023-07-10    35413750.00\n",
      "12                  2023-07-11  -290907519.17\n",
      "13                  2023-07-12    38414658.33\n",
      "14                  2023-07-13    57122723.42\n",
      "15                  2023-07-14    25475139.25\n",
      "16                  2023-07-17    24032500.00\n",
      "17                  2023-07-18   184833287.50\n",
      "18                  2023-07-19    29295992.00\n",
      "19                  2023-07-20    19018497.33\n",
      "20                  2023-07-21    10656583.33\n",
      "21                  2023-07-24    52084800.00\n",
      "22                  2023-07-25   312507298.75\n",
      "23                  2023-07-26    63042750.00\n",
      "24                  2023-07-27    44068175.00\n",
      "25                  2023-07-28    15605025.00\n",
      "26                  2023-07-31      918166.67\n",
      "27                  2023-08-01   272356000.00\n",
      "28                  2023-08-02       48416.67\n",
      "29                  2023-08-03     1022500.00\n",
      "30                  2023-08-04     1277516.67\n",
      "31                  2023-08-07    11958333.33\n",
      "32                  2023-08-08   124226583.33\n",
      "33                  2023-08-09           0.00\n",
      "34                  2023-08-10       83333.33\n",
      "35                  2023-08-11       25000.00\n",
      "36                  2023-08-14    11215833.33\n",
      "37                  2023-08-15    75025083.33\n",
      "38                  2023-08-16       17791.67\n",
      "39                  2023-08-17       22500.00\n",
      "40                  2023-08-18      460833.33\n",
      "41                  2023-08-21       21583.33\n",
      "42                  2023-08-22    15444108.33\n",
      "43                  2023-08-23     1666666.67\n",
      "44  9999-12-31T23:59:59.999999           0.00\n",
      "Daily Volumes\n"
     ]
    }
   ],
   "source": [
    "# Adding new Date object column to data\n",
    "tbill2Y['Trade Time Date'] = clean_dates2Y\n",
    "tbill2Y['Ask Time Date'] = clean_asks2Y\n",
    "\n",
    "# Calculating the total volume on each specific day     \n",
    "day_volumes = tbill2Y.groupby(['Trade Time Date'])['Trade Volume'].sum()\n",
    "\n",
    "# Getting all the unique dates from Trade Time Date\n",
    "unique_dates = tbill2Y['Trade Time Date'].unique()\n",
    "\n",
    "# Creating Average Hourly Trading Volumes from Daily Volumes in Dictionary\n",
    "average_volume_daily = {} #key is date, value is total_volume\n",
    "\n",
    "# Creating dictionary around unique dates, and summed daily volumes\n",
    "for day, vol in zip(unique_dates, day_volumes):\n",
    "    \n",
    "    # Calculate the average volume for the date and store it in the dictionary\n",
    "    average_volume_daily[day] = vol / 12.0\n",
    "\n",
    "# Splitting into lists of Dates, Volumes \n",
    "dates = average_volume_daily.keys()\n",
    "hourly_volumes = average_volume_daily.values()\n",
    "\n",
    "# Print Dates, Volumes\n",
    "# print(dates)\n",
    "# print(daily_volumes)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "# pprint.pprint(average_volume_daily)\n",
    "\n",
    "# Formatting Float in Pandas\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# Print the resulting list\n",
    "daily_volumes = pd.DataFrame()\n",
    "daily_volumes['Trading Day'] = dates\n",
    "daily_volumes['Hourly Volume'] = hourly_volumes\n",
    "print(daily_volumes)\n",
    "\n",
    "print(\"Daily Volumes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7168c29",
   "metadata": {},
   "source": [
    "# Simulating Price and Spread Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6568942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Use Cox-Ingersoll-Ross Model (CIR) model to simulate bond yield process (approximation of price process)\n",
    "#2) Use GARCH model to simulate bid-ask spreads in one step ahead forecasts\n",
    "#3) Z is simulated price, ask is Zu, bid is Zl, utilize to calculate daily portfolio value and loss\n",
    "#4) Calculate compounded interest loss\n",
    "#5) Add final portfolio loss to interest loss, print resuslts of all simulations\n",
    "#OTHER NOTES#\n",
    "#determine what k value we want to keep, assume constant k, $50B issue size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb5f929-9673-47db-86b0-9281e41d9440",
   "metadata": {},
   "source": [
    "# (HELPER FUNCTION) Calculate instantaneous LP position value as a function of k, Zl (bid), Zu (ask), and Z (price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "60f46c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_t(k, Z, Zl, Zu):\n",
    "    if Zl < Z < Zu:\n",
    "        xi = k * (Z**(1/2) - (Zl)**(1/2))\n",
    "        yi = k * (Z**(-1/2) - Zu**(-1/2))\n",
    "        alpha = xi + yi * Z\n",
    "    elif Z < Zl:\n",
    "        xi = 0\n",
    "        yi = k * ((Zl)**(-1/2) - (Zu)**(-1/2))\n",
    "        alpha = xi + yi * Z\n",
    "    elif Z > Zu:\n",
    "        xi = k * ((Zu)**(1/2) - (Zl)**(1/2))\n",
    "        yi = 0\n",
    "        alpha = xi + yi * Z\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4625fbe-5794-4723-93a7-1ecfb11b5f2f",
   "metadata": {},
   "source": [
    "# Calculating Historical Midpoint between Bid and Ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16a31446",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_bid_data = tbill2Y[\"Bid\"]\n",
    "historical_ask_data = tbill2Y[\"Ask\"]\n",
    "historical_midpoint = (historical_bid_data + historical_ask_data) / 2\n",
    "historical_spread = abs(historical_bid_data - historical_ask_data)\n",
    "# historical_midpoint\n",
    "\n",
    "print(\"Calculated Historical Midpoint and Historical Spreads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce940f-734b-4067-9389-78241f116246",
   "metadata": {},
   "source": [
    "# (HELPER FUNCTION) Calculating Price to Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6b4556a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_to_yield(price, face_value, coupon_rate, coupon_frequency, current_date, maturity_date):\n",
    "    time_to_maturity_days = (maturity_date - current_date).days\n",
    "    time_to_maturity_hours = time_to_maturity_days * 24  # Convert to hours\n",
    "    \n",
    "    full_coupon_periods = int(time_to_maturity_hours / (365.0 * 24 / coupon_frequency))\n",
    "    partial_coupon_period_hours = time_to_maturity_hours % (365.0 * 24 / coupon_frequency)\n",
    "    \n",
    "    cash_flows = [(coupon_rate * face_value) / coupon_frequency] * full_coupon_periods\n",
    "    \n",
    "    # Handle the partial coupon period\n",
    "    if partial_coupon_period_hours > 0:\n",
    "        partial_coupon_payment = (coupon_rate * face_value * partial_coupon_period_hours) / (365.0 * 24)\n",
    "        cash_flows.append(partial_coupon_payment)\n",
    "    \n",
    "    cash_flows[-1] += face_value  # Add the face value at maturity\n",
    "    yield_value = np.nan\n",
    "    \n",
    "    try:\n",
    "        yield_value = npf.irr([-price] + cash_flows)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    return yield_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8bf445-754e-425c-ac08-fc8c3e1732b7",
   "metadata": {},
   "source": [
    "# (HELPER FUNCTION) Estimate CIR model parameters using historical yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7f19a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05        1.05484352 -0.00940215  0.03      ]\n"
     ]
    }
   ],
   "source": [
    "def cir_likelihood(parameters, data):\n",
    "    mu, sigma, kappa, theta = parameters\n",
    "    dt = 1 / (252.0 * 12)  # Hourly data assumed\n",
    "    n = len(data)\n",
    "    log_likelihood = 0.0\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        Zl = data[i - 1]\n",
    "        Z = data[i]\n",
    "        Z_diff = Z - Zl\n",
    "        gamma = np.sqrt(kappa**2 + 2 * sigma**2)\n",
    "        \n",
    "        log_likelihood += (\n",
    "            -(n - 1) * (np.log(2 * gamma) - np.log(sigma))\n",
    "            - (kappa + gamma) * Z_diff\n",
    "            - 2 * np.log((2 * gamma * np.exp(kappa + gamma * dt)) / (2 * gamma + (kappa + gamma) * (np.exp(gamma * dt) - 1)))\n",
    "        )\n",
    "    \n",
    "    return -log_likelihood\n",
    "\n",
    "initial_parameters = [0.05, 0.1, 0.2, 0.03]  # Initial guesses for parameters\n",
    "result = minimize(cir_likelihood, initial_parameters, args=(historical_midpoint,), method='L-BFGS-B')\n",
    "mu, sigma, kappa, theta = result.x\n",
    "print(result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd77377-6433-473f-bb26-48a119656a40",
   "metadata": {},
   "source": [
    "# Simulate bond yields based on the estimated CIR parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e34333ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1  # Time to maturity, years\n",
    "n_simulations = 1000  # Num of sims\n",
    "n_periods = 252 * 12  # Num of hourly periods in a year\n",
    "coupon_rate = 0.04625  \n",
    "coupon_frequency = 2  \n",
    "\n",
    "simulated_yields = np.zeros((n_simulations, n_periods + 1)) #init array\n",
    "\n",
    "for i in range(n_simulations):\n",
    "    dt = T / n_periods\n",
    "    current_date = tbill2Y[\"Bid Time\"][0] \n",
    "    maturity_date = current_date + pd.DateOffset(years=T)\n",
    "    bond_price = historical_midpoint.iloc[0]  # Initial bond price at first midpoint value\n",
    "    \n",
    "    for j in range(1, len(historical_midpoint)):\n",
    "        bond_yield = price_to_yield(bond_price, 1000, coupon_rate, coupon_frequency, current_date, maturity_date)\n",
    "        Z_diff = bond_yield - historical_midpoint.iloc[j - 1]\n",
    "        gamma = np.sqrt(kappa**2 + 2 * sigma**2)\n",
    "        bond_yield += kappa * (theta - bond_yield) * dt + sigma * np.sqrt(bond_yield) * np.random.normal(0, np.sqrt(dt))  # CIR process\n",
    "        bond_price = 1000 / ((1 + bond_yield / coupon_frequency) ** (coupon_frequency * (maturity_date - current_date).days / (365 * 24)))  # Convert yield to price\n",
    "        simulated_yields[i, j] = bond_yield"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d885891c",
   "metadata": {},
   "source": [
    "# Replacing Spread And Volume Simulation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a18ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: -1850.056910732715\n",
      "        x: [-1.553e-04  4.803e-03  1.119e-02]\n",
      "      nit: 54\n",
      "      jac: [-7.935e-01 -1.590e+00 -8.907e-01]\n",
      "     nfev: 316\n",
      "     njev: 79\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "# Estimating OU (Ornstein–Uhlenbeck) Process Paramters for Spread Simulation\n",
    "\n",
    "# Historical spread data is used from above calculation\n",
    "\n",
    "# Function to calculate the OU likelihood\n",
    "def ou_likelihood(parameters, data):\n",
    "    mean_reversion, vol, initial_spread_min = parameters\n",
    "    dt = 1  # Time step (you can adjust this based on your data frequency)\n",
    "    log_likelihood = 0.0\n",
    "    initial_spread = initial_spread_min\n",
    "    \n",
    "    for i in range(1, len(historical_spread)):\n",
    "        spread_diff = historical_spread[i] - initial_spread\n",
    "        log_likelihood += -0.5 * (spread_diff / vol) ** 2\n",
    "        log_likelihood -= 0.5 * np.log(2 * np.pi * vol ** 2 * dt)\n",
    "        initial_spread += mean_reversion * (initial_spread_min - spread) * dt\n",
    "\n",
    "    return -log_likelihood\n",
    "\n",
    "# Initial parameter guesses\n",
    "intial_mean_reversion = 0.1\n",
    "intial_vol = 0.05\n",
    "intial_min_arg = historical_spread[0]\n",
    "\n",
    "# Packing them into parameter tupe\n",
    "initial_parameters = (intial_mean_reversion, intial_vol, intial_min_arg)\n",
    "\n",
    "# Minimize the negative log-likelihood to estimate OU parameters\n",
    "result = minimize(ou_likelihood, initial_parameters, args=(historical_spread,), method='L-BFGS-B')\n",
    "print(result)\n",
    "\n",
    "# Extract estimated parameters\n",
    "mean_reversion, volatility, initial_spread = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d84155fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulating Spreads with OU Process\n",
    "\n",
    "n_simulations = 1000  # Number of simulations\n",
    "n_periods = len(historical_spread)  # Number of periods to simulate\n",
    "\n",
    "simulated_spreads = np.zeros((n_simulations, n_periods))\n",
    "\n",
    "for i in range(n_simulations):\n",
    "    spread = initial_spread\n",
    "    for j in range(n_periods):\n",
    "        spread += mean_reversion * (initial_spread - spread) * dt + volatility * np.sqrt(dt) * np.random.normal(0, 1)\n",
    "        simulated_spreads[i, j] = spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19c3b4fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'historical_hourly_vwap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m simulated_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHourly_Volume\u001b[39m\u001b[38;5;124m'\u001b[39m: simulated_hourly_volume})\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Simulate VWAP prices based on historical VWAP data\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Assuming a simple linear relationship between volume and price\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m simulated_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVWAP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minterp(simulated_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHourly_Volume\u001b[39m\u001b[38;5;124m'\u001b[39m], np\u001b[38;5;241m.\u001b[39mcumsum(historical_hourly_volume), \u001b[43mhistorical_hourly_vwap\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'historical_hourly_vwap' is not defined"
     ]
    }
   ],
   "source": [
    "#Simulating Volume using VWAP and volume and Poisson Process\n",
    "\n",
    "# Replace with volume data\n",
    "\n",
    "# Calculate the average trading rate (λ) from historical data\n",
    "# Calculate sums of Hourly Volume\n",
    "total_historical_sum = 0\n",
    "for hourly_volume in historical_hourly_volume:\n",
    "    total_historical_sum += hourly_volume\n",
    "average_historical_trading_rate = total_historical_sum / len(historical_hourly_volume)\n",
    "\n",
    "# Simulate trading volume using a Poisson process\n",
    "simulated_hourly_volume = np.random.poisson(average_historical_trading_rate, len(historical_hourly_volume))\n",
    "\n",
    "# Calculate sums of Hourly Volume\n",
    "total_simulated_sum = 0\n",
    "for hourly_volume in simulated_hourly_volume:\n",
    "    total_simulated_sum += hourly_volume\n",
    "average_simulated_trading_rate = total_simulated_sum / len(simulated_hourly_volume)\n",
    "\n",
    "# Adjust for daily variation (for example, increase trading rate during high-activity hours)\n",
    "# Can customize this adjustment based on your market's characteristics\n",
    "simulated_hourly_volume[0] *= 1.2  # Increase volume during market open\n",
    "simulated_hourly_volume[-1] *= 1.2  # Increase volume during market close\n",
    "\n",
    "# Normalize simulated volume to match historical data\n",
    "np.multiply(simulated_hourly_volume, total_historical_sum / total_simulated_sum)\n",
    "\n",
    "# Create a DataFrame to store the simulated volume data\n",
    "simulated_data = pd.DataFrame({'Hourly_Volume': simulated_hourly_volume})\n",
    "\n",
    "# Simulate VWAP prices based on historical VWAP data\n",
    "# Assuming a simple linear relationship between volume and price\n",
    "simulated_data['VWAP'] = np.interp(simulated_data['Hourly_Volume'], np.cumsum(historical_hourly_volume), historical_hourly_vwap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "69d71f43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forecasted_spreads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m daily_profits \u001b[38;5;241m=\u001b[39m \u001b[43mforecasted_spreads\u001b[49m \u001b[38;5;241m*\u001b[39m simulated_volumes \u001b[38;5;241m*\u001b[39m fee_rate \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Divide by 2 to account for bid and ask\u001b[39;00m\n\u001b[1;32m      3\u001b[0m total_daily_pnl \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(portfolio_losses) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39marray(daily_opportunity_cost) \u001b[38;5;241m+\u001b[39m daily_profits\n",
      "\u001b[0;31mNameError\u001b[0m: name 'forecasted_spreads' is not defined"
     ]
    }
   ],
   "source": [
    "daily_profits = forecasted_spreads * simulated_volumes * fee_rate / 2  # Divide by 2 to account for bid and ask\n",
    "\n",
    "total_daily_pnl = np.array(portfolio_losses) + np.array(daily_opportunity_cost) + daily_profits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a3763-f1f8-41d2-96ff-e813834deba4",
   "metadata": {},
   "source": [
    "# Plot the LP PnL time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c1d8c26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_daily_pnl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtotal_daily_pnl\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLP PnL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLiquidity Provider (LP) PnL Over Time\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_daily_pnl' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(total_daily_pnl, label='LP PnL')\n",
    "plt.title('Liquidity Provider (LP) PnL Over Time')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('PnL')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcff95d-f5a7-4b12-bd83-fbc46c6ebd7d",
   "metadata": {},
   "source": [
    "# Create a heatmap of LP PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ed897-6e27-4c93-b7d2-4424a9f4b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(np.array([total_daily_pnl]), annot=True, cmap='coolwarm', fmt='.2f', cbar=True)\n",
    "plt.title('Liquidity Provider (LP) PnL Heatmap')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Simulation')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
